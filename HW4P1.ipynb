{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacobrast/11785-hw4p1/blob/main/HW4P1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "oxiZ42B4SwQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb819b10-36f2-424e-de3c-a728865fa1f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'batch_size': 32,\n",
        "    'seq_length': 128,\n",
        "    'lr': 1,\n",
        "    'sgd_momentum' : 0,\n",
        "    'sgd_weight_decay' : 0,\n",
        "    'num_epochs': 10,\n",
        "    'emb_dim' : 400,\n",
        "    'hidden_size' : 1150,\n",
        "    'dropout' : 0.0,\n",
        "    'lstm_num_layers': 3,\n",
        "    \"small_data\" : False\n",
        "}"
      ],
      "metadata": {
        "id": "0F6rAHL_qe05"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_softmax(x, axis):\n",
        "    ret = x - np.max(x, axis=axis, keepdims=True)\n",
        "    lsm = np.log(np.sum(np.exp(ret), axis=axis, keepdims=True))\n",
        "    return ret - lsm\n",
        "\n",
        "\n",
        "def array_to_str(arr, vocab):\n",
        "    return \" \".join(vocab[a] for a in arr)\n",
        "\n",
        "\n",
        "def test_prediction(out, targ):\n",
        "    out = log_softmax(out, 1)\n",
        "    nlls = out[np.arange(out.shape[0]), targ]\n",
        "    nll = -np.mean(nlls)\n",
        "    return nll\n",
        "\n",
        "\n",
        "def test_generation(inp, pred, vocab):\n",
        "    outputs = u\"\"\n",
        "    for i in range(inp.shape[0]):\n",
        "        w1 = array_to_str(inp[i], vocab)\n",
        "        w2 = array_to_str(pred[i], vocab)\n",
        "        outputs += u\"Input | Output #{}: {} | {}\\n\".format(i, w1, w2)\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "vEGyL58v6-4V"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nhTnY4254Kk",
        "outputId": "77ad9d70-06f8-4a72-e82a-91da1f7017d4"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf \"/content/drive/MyDrive/Colab Notebooks/handout_hw4.tar\""
      ],
      "metadata": {
        "id": "SZlNp5GF6apm"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "x5znxQhLSwRC"
      },
      "outputs": [],
      "source": [
        "# load all that we need\n",
        "\n",
        "dataset = np.load('handout/dataset/wiki.train.npy', allow_pickle=True)\n",
        "devset = np.load('handout/dataset/wiki.valid.npy', allow_pickle=True)\n",
        "fixtures_pred = np.load('handout/fixtures/prediction.npz')  # dev\n",
        "fixtures_gen = np.load('handout/fixtures/generation.npy')  # dev\n",
        "fixtures_pred_test = np.load('handout/fixtures/prediction_test.npz')  # test\n",
        "fixtures_gen_test = np.load('handout/fixtures/generation_test.npy')  # test\n",
        "vocab = np.load('handout/dataset/vocab.npy')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(array_to_str(fixtures_gen[1], vocab))\n",
        "print(array_to_str(fixtures_gen_test[0], vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nw97-DiTHu9",
        "outputId": "7f3c31ee-f600-4bfe-b99f-17d2f623e6ef"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<unk> , where he remained on loan until 30 June 2010 . <eol> = = = Return to Manchester United\n",
            "Mark Strong and Derek Jacobi . <unk> starred as \" Darren \" , in the 2005 theatre productions of the Philip Ridley play Mercury Fur . It was performed at\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "OZNrJ8XvSwRF"
      },
      "outputs": [],
      "source": [
        "# data loader\n",
        "\n",
        "class DataLoaderForLanguageModeling(DataLoader):\n",
        "    \"\"\"\n",
        "        TODO: Define data loader logic here\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, batch_size, seq_length, shuffle=True):\n",
        "        self.shuffle = shuffle\n",
        "        #if shuffle:\n",
        "            #np.random.shuffle(dataset)\n",
        "        self.dataset = dataset\n",
        "        #self.data = np.concatenate(dataset)\n",
        "        self.batch_size = batch_size\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "        data = np.concatenate(self.dataset)\n",
        "        self.len = int((data.shape[0] - self.seq_length - 1) / (self.batch_size * self.seq_length))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "  \n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"\n",
        "            You may implement some of the techniques in https://arxiv.org/pdf/1708.02182.pdf\n",
        "            example: Variable length backpropagation sequences (Section 4.1)\n",
        "        \"\"\"\n",
        "        # 1. Randomly shuffle all the articles from the WikiText-2 dataset.\n",
        "        # 2. Concatenate all text in one long string.\n",
        "        # 3. Group the sequences into batches.\n",
        "        # 4. Run a loop that returns a tuple of (input, label) on every iteration with yield.\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.dataset)\n",
        "\n",
        "        if config[\"small_data\"]:\n",
        "            data = np.concatenate(self.dataset)[:10000]\n",
        "\n",
        "        else:\n",
        "            data = np.concatenate(self.dataset)\n",
        "\n",
        "        for i in range(0, data.shape[0] - self.seq_length - 1, self.batch_size * self.seq_length):\n",
        "            #Question: what data format should I use to return the batch? A: list\n",
        "            #Question: how do I deal with the last item? A: if statement\n",
        "            inputs = []\n",
        "            targets = []\n",
        "\n",
        "            if (i + self.batch_size * self.seq_length > data.shape[0]):\n",
        "                #batch_size = data.shape[0] - i\n",
        "                #throw data away\n",
        "                break\n",
        "\n",
        "            ind = i\n",
        "\n",
        "            for j in range(self.batch_size):\n",
        "                  inputs.append(data[ind:ind+self.seq_length])\n",
        "                  targets.append(data[ind+1:ind+1+self.seq_length])\n",
        "                  ind = ind + self.seq_length            \n",
        "            \n",
        "            inputs = torch.from_numpy(np.stack(inputs))\n",
        "            targets = torch.from_numpy(np.stack(targets))\n",
        "            yield inputs, targets      "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Code to test my dataloader implementation\n",
        "\n",
        "# loader = DataLoaderForLanguageModeling(\n",
        "#     dataset=dataset, \n",
        "#     batch_size=1,\n",
        "#     seq_length=3,\n",
        "#     shuffle=True\n",
        "# )\n",
        "\n",
        "# j = 0\n",
        "# i, (inputs, targets)  = next(enumerate(loader))\n",
        "\n",
        "# print(inputs)\n",
        "# print(targets)"
      ],
      "metadata": {
        "id": "d-yYWSsaAYz0"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "Zt-7YsTYSwRI"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, vocab_size:int, embedding_dim:int, hidden_size:int):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        bidirectional = True\n",
        "        self.emb_size = embedding_dim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embeddings = nn.Embedding(self.vocab_size, self.emb_size, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(self.emb_size, self.hidden_size, num_layers=config['lstm_num_layers'], batch_first=True, bidirectional=bidirectional, dropout=config[\"dropout\"])\n",
        "\n",
        "        if bidirectional:\n",
        "            self.mlp = nn.Linear(2 * hidden_size, vocab_size).to(device)\n",
        "            \n",
        "\n",
        "    def forward(self, x, h=None, c=None, get_hidden=False):\n",
        "        # Feel free to add extra arguments to forward (like an argument to pass in the hiddens)\n",
        "        embeds = self.embeddings(x)\n",
        "\n",
        "        if h!=None and c!=None:\n",
        "            o, (hidden, cell) = self.lstm(embeds, (h, c))\n",
        "\n",
        "        else:\n",
        "            o, (hidden, cell) = self.lstm(embeds)\n",
        "\n",
        "        x = self.mlp(o)\n",
        "\n",
        "        if get_hidden:\n",
        "            return x, (hidden, cell)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "\n",
        "# Let the embedding size be varaible\n",
        "class Encoder(nn.Module):\n",
        "    #def __init__(self, emb_size, hidden_size, vocab_size, pad_idx, num_layers, bidirectional):\n",
        "    def __init__(self, emb_size, hidden_size, vocab_size, num_layers, bidirectional):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embeddings = nn.Embedding(self.vocab_size, self.emb_size, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(self.emb_size, self.hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeds = self.embeddings(x)\n",
        "        h, _ = self.lstm(embeds)\n",
        "\n",
        "        return h\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    \"\"\"\n",
        "        The model should have the following layers:\n",
        "          1) Embedding layer. We can use nn.Embedding.\n",
        "          2) Encoder. This will be a multilayer LSTM (to begin)\n",
        "          3) Decoder. Another multilayer LSTM.\n",
        "\n",
        "        Questions:\n",
        "          1. What should I use as the dimensions of my word embedding?\n",
        "            a: Let this be variable. We can set it as a parameter.\n",
        "          2. How to define my encoder and decoder?\n",
        "            a: For now, just use a standard MLP for the decoder.\n",
        "          3. Can I train word embeddings in my dataset?\n",
        "            a: Not sure what this means. We can train word embeddings in the encoder, yes. For the encoder/decoder model, word embeddings\n",
        "               may or may not be shared between encoder and decoder. Probably should be, but might work without?\n",
        "          4. Where is the sequence length defined?\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size:int, embedding_dim:int, hidden_size:int):\n",
        "        super(Model, self).__init__()\n",
        "        encoder_layers = 2\n",
        "        bidirectional = True\n",
        "        self.encoder = Encoder(embedding_dim, hidden_size, vocab_size, encoder_layers, bidirectional).to(device)\n",
        "\n",
        "        if bidirectional:\n",
        "            # nn.linear input shape: B * input_size\n",
        "            # nn.linear output shape: B * output_size\n",
        "            #self.mlp = nn.linear(2 * encoder_layers * hidden_size, vocab_size)\n",
        "            self.mlp = nn.Linear(2 * hidden_size, vocab_size).to(device)\n",
        "\n",
        "        #else:\n",
        "        # throw error for now\n",
        "\n",
        "        self.model = nn.Sequential(self.encoder, self.mlp).to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Feel free to add extra arguments to forward (like an argument to pass in the hiddens)\n",
        "\n",
        "        # What are the dimensions of x?\n",
        "        # How do I run only the last hidden state through the MLP?\n",
        "\n",
        "        # h_n has dimensions D * num_layers, N, H_out\n",
        "        #   where num_layers is set to 2 (for now), and D is 2 for bidirectional\n",
        "        #   N is batch size\n",
        "        #   h_out is the hidden size\n",
        "\n",
        "\n",
        "        # #Need to modify. This will only predict the final word. We need to predict the next word for each word in the sequence.\n",
        "        # _, (hidden, cell) = self.encoder(x)\n",
        "        # out = self.MLP(hidden)  \n",
        "\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "fbGhv2MlT_Sh"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Code to test model\n",
        "# model = Model(vocab.size, embedding_dim=100, hidden_size=100).to(device)\n",
        "\n",
        "# loader = DataLoaderForLanguageModeling(\n",
        "#     dataset=dataset, \n",
        "#     batch_size=2,\n",
        "#     seq_length=3,\n",
        "#     shuffle=True\n",
        "# )\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# data = enumerate(loader)"
      ],
      "metadata": {
        "id": "GpZir0WqFJwF"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_num, (inputs, targets) = next(data)"
      ],
      "metadata": {
        "id": "J-gY7I4sFWNu"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs = inputs.to(device)\n",
        "# outputs = model(inputs)\n",
        "# targets = targets.to(device)\n",
        "\n",
        "# print(outputs)\n",
        "\n",
        "# targets = torch.flatten(targets).to(torch.int64)\n",
        "# outputs = torch.flatten(outputs, start_dim=0, end_dim=1)\n",
        "\n",
        "# loss = criterion(outputs, targets)\n",
        "\n",
        "# print(loss)\n",
        "\n",
        "# #loss.backward()"
      ],
      "metadata": {
        "id": "rcJybLVYQips"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "kIvZOIfjSwRK"
      },
      "outputs": [],
      "source": [
        "# model trainer\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, loader, max_epochs=1, run_id='exp'):\n",
        "        \"\"\"\n",
        "            Use this class to train your model\n",
        "        \"\"\"\n",
        "        # feel free to add any other parameters here\n",
        "        self.model = model\n",
        "        self.loader = loader\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.predictions = []\n",
        "        self.predictions_test = []\n",
        "        self.generated_logits = []\n",
        "        self.generated = []\n",
        "        self.generated_logits_test = []\n",
        "        self.generated_test = []\n",
        "        self.epochs = 0\n",
        "        self.max_epochs = max_epochs\n",
        "        self.run_id = run_id\n",
        "        \n",
        "        # TODO: Define your optimizer and criterion here\n",
        "        # feel free to define a learning rate scheduler as well if you want\n",
        "        self.optimizer = torch.optim.SGD(model.parameters(), lr=config['lr'], momentum=config['sgd_momentum'], weight_decay=config['sgd_weight_decay'])\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def train(self):\n",
        "        self.model.train() # set to training mode\n",
        "        epoch_loss = 0\n",
        "        num_batches = 0\n",
        "        batch_bar = tqdm(total=len(self.loader), dynamic_ncols=True, leave=False, position=0, desc='Train', ncols=5)\n",
        "        for batch_num, (inputs, targets) in enumerate(self.loader):\n",
        "            epoch_loss += self.train_batch(inputs, targets)\n",
        "            batch_bar.set_postfix(\n",
        "                loss=\"{:.04f}\".format(float(epoch_loss / (batch_num + 1)))\n",
        "                )\n",
        "            batch_bar.update()\n",
        "        epoch_loss = epoch_loss / (batch_num + 1)\n",
        "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
        "                      % (self.epochs + 1, self.max_epochs, epoch_loss))\n",
        "        self.train_losses.append(epoch_loss)\n",
        "\n",
        "    def train_batch(self, inputs, targets):\n",
        "        \"\"\" \n",
        "            TODO: Define code for training a single batch of inputs\n",
        "            \n",
        "            :return \n",
        "                    (float) loss value\n",
        "        \"\"\"\n",
        "\n",
        "        self.optimizer.zero_grad() # Zero gradients\n",
        "\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        \n",
        "        outputs = self.model(inputs)\n",
        "\n",
        "        targets = torch.flatten(targets).to(torch.int64)\n",
        "        outputs = torch.flatten(outputs, start_dim=0, end_dim=1)\n",
        "\n",
        "        loss = self.criterion(outputs, targets)\n",
        "\n",
        "        # Update no. of correct predictions & loss as we iterate\n",
        "        #num_correct += int((torch.argmax(outputs, axis=1) == targets).sum())\n",
        "        #total_loss += float(loss.item())\n",
        "        \n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss\n",
        "\n",
        "    \n",
        "    def test(self):\n",
        "        # don't change these\n",
        "        self.model.eval() # set to eval mode\n",
        "        predictions = TestLanguageModel.predict(fixtures_pred['inp'], self.model) # get predictions\n",
        "        self.predictions.append(predictions)\n",
        "        #generated_logits = TestLanguageModel.generate(fixtures_gen, 10, self.model) # generated predictions for 10 words\n",
        "        #generated_logits_test = TestLanguageModel.generate(fixtures_gen_test, 10, self.model)\n",
        "        nll = test_prediction(predictions, fixtures_pred['out'])\n",
        "        #generated = test_generation(fixtures_gen, generated_logits, vocab)\n",
        "        #generated_test = test_generation(fixtures_gen_test, generated_logits_test, vocab)\n",
        "        self.val_losses.append(nll)\n",
        "        \n",
        "        #self.generated.append(generated)\n",
        "        #self.generated_test.append(generated_test)\n",
        "        #self.generated_logits.append(generated_logits)\n",
        "        #self.generated_logits_test.append(generated_logits_test)\n",
        "        \n",
        "        # generate predictions for test data\n",
        "        predictions_test = TestLanguageModel.predict(fixtures_pred_test['inp'], self.model) # get predictions\n",
        "        self.predictions_test.append(predictions_test)\n",
        "            \n",
        "        print('[VAL]  Epoch [%d/%d]   Loss: %.4f'\n",
        "                      % (self.epochs + 1, self.max_epochs, nll))\n",
        "        self.epochs += 1\n",
        "\n",
        "        return nll\n",
        "\n",
        "    def save(self):\n",
        "        # don't change these\n",
        "        model_path = os.path.join('experiments', self.run_id, 'model-{}.pkl'.format(self.epochs))\n",
        "        torch.save({'state_dict': self.model.state_dict()},\n",
        "            model_path)\n",
        "        np.save(os.path.join('experiments', self.run_id, 'predictions-{}.npy'.format(self.epochs)), self.predictions[-1])\n",
        "        np.save(os.path.join('experiments', self.run_id, 'predictions-test-{}.npy'.format(self.epochs)), self.predictions_test[-1])\n",
        "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-{}.npy'.format(self.epochs)), self.generated_logits[-1])\n",
        "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-test-{}.npy'.format(self.epochs)), self.generated_logits_test[-1])\n",
        "        with open(os.path.join('experiments', self.run_id, 'generated-{}.txt'.format(self.epochs)), 'w') as fw:\n",
        "            fw.write(self.generated[-1])\n",
        "        with open(os.path.join('experiments', self.run_id, 'generated-{}-test.txt'.format(self.epochs)), 'w') as fw:\n",
        "            fw.write(self.generated_test[-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "xPI7_kZRSwRN"
      },
      "outputs": [],
      "source": [
        "from re import X\n",
        "class TestLanguageModel:\n",
        "    def predict(inp, model):\n",
        "        \"\"\"\n",
        "            TODO: write prediction code here\n",
        "            \n",
        "            :param inp:\n",
        "            :return: a np.ndarray of logits\n",
        "\n",
        "            Question: What are logits?\n",
        "        \"\"\"\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        x = torch.from_numpy(inp)\n",
        "        x = x.to(device)\n",
        "\n",
        "        y = model(x)\n",
        "\n",
        "        out = y[:,-1,:]\n",
        "\n",
        "        return out.detach().cpu().numpy()\n",
        "\n",
        "        \n",
        "    def generate(inp, forward, model):\n",
        "        \"\"\"\n",
        "            TODO: write generation code here\n",
        "\n",
        "            Generate a sequence of words given a starting sequence.\n",
        "            :param inp: Initial sequence of words (batch size, length)\n",
        "            :param forward: number of additional words to generate\n",
        "            :return: generated words (batch size, forward)\n",
        "        \"\"\"   \n",
        "        model.eval()\n",
        "\n",
        "        batch_size = inp.shape[0]\n",
        "\n",
        "        x = torch.from_numpy(inp)\n",
        "        x = x.to(device)\n",
        "\n",
        "        softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "        y, (h, c) = model.forward(x, get_hidden=True)\n",
        "\n",
        "        out = torch.zeros((batch_size, forward))\n",
        "        nextword = torch.argmax(softmax(y), dim=2)[:, -1]\n",
        "\n",
        "        out[:, 0] = nextword\n",
        "\n",
        "        nextword = nextword.unsqueeze(dim=0)\n",
        "\n",
        "        hidden_size = h.shape[2]\n",
        "        unknown = h.shape[0]\n",
        "        \n",
        "        h = h[:, -1, :].reshape((unknown, 1, hidden_size)).contiguous()\n",
        "        c = c[:, -1, :].reshape((unknown, 1, hidden_size)).contiguous()\n",
        "\n",
        "        for i in range(1, forward):\n",
        "            y, (h, c) = model.forward(nextword, h=h, c=c, get_hidden=True)\n",
        "            nextword = torch.argmax(softmax(y), dim=2)\n",
        "\n",
        "            out[:, i] = nextword\n",
        "\n",
        "        return out.to(torch.int32).detach().cpu().numpy()\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "2HCVG5YISwRW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "571b4a16-3e86-4f46-b351-148ba8bf1413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving models, predictions, and generated words to ./experiments/1669407891\n"
          ]
        }
      ],
      "source": [
        "run_id = str(int(time.time()))\n",
        "if not os.path.exists('./experiments'):\n",
        "    os.mkdir('./experiments')\n",
        "os.mkdir('./experiments/%s' % run_id)\n",
        "print(\"Saving models, predictions, and generated words to ./experiments/%s\" % run_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "DbHH6zXTSwRa"
      },
      "outputs": [],
      "source": [
        "model = Model(vocab.size, embedding_dim=config['emb_dim'], hidden_size=config['hidden_size']).to(device)\n",
        "\n",
        "loader = DataLoaderForLanguageModeling(\n",
        "    dataset=dataset, \n",
        "    batch_size=config['batch_size'], \n",
        "    shuffle=True,\n",
        "    seq_length=config['seq_length']\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model, \n",
        "    loader=loader, \n",
        "    max_epochs=config['num_epochs'], \n",
        "    run_id=run_id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "0wrqnwie7jrf"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "7D8wTJkBSwRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4e7f09-92cc-4747-82c9-95ed3eedc6b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [1/10]   Loss: 5.4415\n",
            "[VAL]  Epoch [1/10]   Loss: 7.8124\n",
            "Saving model, predictions and generated output for epoch 0 with NLL: 7.812419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [2/10]   Loss: 3.4898\n",
            "[VAL]  Epoch [2/10]   Loss: 6.7846\n",
            "Saving model, predictions and generated output for epoch 1 with NLL: 6.784633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [3/10]   Loss: 2.7098\n",
            "[VAL]  Epoch [3/10]   Loss: 7.5985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [4/10]   Loss: 1.8627\n",
            "[VAL]  Epoch [4/10]   Loss: 6.9821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [5/10]   Loss: 1.3404\n",
            "[VAL]  Epoch [5/10]   Loss: 6.5951\n",
            "Saving model, predictions and generated output for epoch 4 with NLL: 6.5951033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [6/10]   Loss: 1.0278\n",
            "[VAL]  Epoch [6/10]   Loss: 6.5354\n",
            "Saving model, predictions and generated output for epoch 5 with NLL: 6.5353613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [7/10]   Loss: 0.8206\n",
            "[VAL]  Epoch [7/10]   Loss: 6.3515\n",
            "Saving model, predictions and generated output for epoch 6 with NLL: 6.351547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [8/10]   Loss: 0.6706\n",
            "[VAL]  Epoch [8/10]   Loss: 6.2563\n",
            "Saving model, predictions and generated output for epoch 7 with NLL: 6.2563114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [9/10]   Loss: 0.5583\n",
            "[VAL]  Epoch [9/10]   Loss: 6.1010\n",
            "Saving model, predictions and generated output for epoch 8 with NLL: 6.100974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]  Epoch [10/10]   Loss: 0.4716\n",
            "[VAL]  Epoch [10/10]   Loss: 6.0396\n",
            "Saving model, predictions and generated output for epoch 9 with NLL: 6.0396147\n"
          ]
        }
      ],
      "source": [
        "best_nll = 1e30 \n",
        "for epoch in range(config['num_epochs']):\n",
        "    trainer.train()\n",
        "    nll = trainer.test()\n",
        "    if nll < best_nll:\n",
        "        best_nll = nll\n",
        "        print(\"Saving model, predictions and generated output for epoch \"+str(epoch)+\" with NLL: \"+ str(best_nll))\n",
        "        #trainer.save()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = torch.tensor(trainer.train_losses, device = 'cpu')\n",
        "val_losses = torch.tensor(trainer.val_losses, device='cpu')"
      ],
      "metadata": {
        "id": "o1yx0_ZYppKC"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "z2FmDqBCSwRf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "ce577f4d-afb6-4899-d5d4-f9c19bcad4c1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Don't change these\n",
        "# plot training curves\n",
        "plt.figure()\n",
        "plt.plot(range(1, trainer.epochs + 1), train_losses, label='Training losses')\n",
        "plt.plot(range(1, trainer.epochs + 1), val_losses, label='Validation losses')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('NLL')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "ipdbmqaGSwRh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "21a36ffe-2631-47d3-f144-b36a928da5f5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-140-e8b85fefb63f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# see generated output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get last generated output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# see generated output\n",
        "print (trainer.generated[-1]) # get last generated output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# runid=1669399860\n",
        "# epoch=10\n",
        "# !cp /content/experiments/{runid}/predictions-test-{epoch}.npy predictions.npy\n",
        "# !cp /content/experiments/{runid}/generated-{epoch}.txt generated.txt\n",
        "# !cp /content/experiments/{runid}/generated_logits-test-{epoch}.npy generated_logits.npy\n",
        "# !cp \"/content/drive/MyDrive/Colab Notebooks/HW4P1.ipynb\" training.ipynb\n",
        "# !tar -cvf handin.tar training.ipynb predictions.npy generated.txt generated_logits.npy\n",
        "# !rm -f training.ipynb predictions.npy"
      ],
      "metadata": {
        "id": "tEIKxMMftVhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('handin.tar') "
      ],
      "metadata": {
        "id": "UnrI_z64A1Og"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}